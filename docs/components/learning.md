# 14 — Learning Engine

## Назначение

Learning Engine — это механизм медленного изменения внутренних параметров Life без оптимизации, целей или оценки эффективности.

**ВАЖНО:** Learning НЕ является:
- ❌ Оптимизацией или reinforcement learning
- ❌ Управлением поведением
- ❌ Системой с целями и намерениями
- ❌ Оценкой эффективности действий

Learning — это только **медленное изменение внутренних параметров** на основе статистики из Memory.

## Текущий статус

✅ **Реализован** (v1.0, Этап 14)
*   Файл: [`src/learning/learning.py`](../../src/learning/learning.py)
*   Интегрирован в Runtime Loop
*   Протестирован: [`src/test/test_learning.py`](../../src/test/test_learning.py)

### ✅ Интеграция параметров

**Параметры Learning теперь используются в системе:**

Параметры `learning_params` (event_type_sensitivity, significance_thresholds, response_coefficients) изменяются Learning Engine и **активно применяются** в:
- ✅ MeaningEngine (интерпретация событий) - `appraisal()`, `response_pattern()`, `process()`
- ✅ Decision Engine (выбор паттернов реакции) - `decide_response()`
- ✅ Action Engine (выполнение действий) - `execute_action()`

**Как используются параметры:**

1. **`event_type_sensitivity`** - используется в `MeaningEngine.appraisal()` для модификации значимости событий на основе обученной чувствительности
2. **`significance_thresholds`** - используется в `MeaningEngine.response_pattern()` и `Decision.decide_response()` для определения порогов значимости
3. **`response_coefficients`** - используется в `MeaningEngine.process()` и `Action.execute_action()` для модификации коэффициентов реакции

**Интеграция с Adaptation:**
- Параметры Learning используются Adaptation Manager для медленной перестройки поведения
- Adaptation создает `adaptation_params` на основе `learning_params`
- Оба набора параметров используются в системе для влияния на поведение

**Статус:** Параметры полностью интегрированы и влияют на поведение системы.

## Архитектурные ограничения

### Абсолютные запреты

1. **Запрет на оптимизацию**
   - ❌ Не усиливает или ослабляет действия
   - ❌ Не выбирает лучший вариант
   - ❌ Не корректирует поведение

2. **Запрет на цели и намерения**
   - ❌ Не работает для достижения цели
   - ❌ Не направлено на результат
   - ❌ Не имеет reward/punishment

3. **Запрет на циклы обратной связи**
   - ❌ Не использует Decision → Action → Feedback как цикл контроля
   - ❌ Не инициирует новые действия
   - ❌ Не корректирует будущие действия напрямую

4. **Запрет на внешнюю зависимость**
   - ❌ Не требует внешних метрик
   - ❌ Не взаимодействует с KPI или success metrics

### Разрешённый минимум

Learning **может**:
- ✅ Постепенно изменять внутренние параметры (макс. 0.01 за раз)
- ✅ Фиксировать изменения без интерпретации
- ✅ Использовать внутреннюю статистику из Memory

Learning **не может**:
- ❌ Оценивать правильность изменений
- ❌ Вмешиваться в Decision или Action
- ❌ Инициировать Feedback

## Реализация

### Основные методы

#### `process_statistics(memory: List[MemoryEntry]) -> Dict`

Анализирует Memory для извлечения статистики:
- Типы событий и их частота
- Паттерны действий из Feedback
- Изменения состояния из Feedback

**ВАЖНО:** Без интерпретации, только сбор статистики.

#### `adjust_parameters(statistics: Dict, current_params: Dict) -> Dict`

Медленно изменяет внутренние параметры на основе статистики:
- Изменение чувствительности к типам событий (`event_type_sensitivity`)
- Изменение порогов значимости (`significance_thresholds`)
- Изменение коэффициентов реакции (`response_coefficients`)

**Ограничения:**
- Максимальное изменение: `MAX_PARAMETER_DELTA = 0.01` за раз
- Минимальное изменение: `MIN_PARAMETER_DELTA = 0.001` (чтобы избежать микро-изменений)
- Изменения основаны на частоте/паттернах, НЕ на оценке эффективности

#### `record_changes(old_params: Dict, new_params: Dict, self_state: SelfState) -> None`

Фиксирует изменения параметров в SelfState без интерпретации.

**Проверки:**
- Убеждается, что изменения медленные (<= 0.01)
- Обновляет `self_state.learning_params`
- Не сохраняет историю изменений, не интерпретирует, не оценивает

### Параметры Learning

Параметры хранятся в `SelfState.learning_params`:

```python
learning_params = {
    "event_type_sensitivity": {
        "noise": 0.2,
        "decay": 0.2,
        "recovery": 0.2,
        "shock": 0.2,
        "idle": 0.2,
    },
    "significance_thresholds": {
        "noise": 0.1,
        "decay": 0.1,
        "recovery": 0.1,
        "shock": 0.1,
        "idle": 0.1,
    },
    "response_coefficients": {
        "dampen": 0.5,
        "absorb": 1.0,
        "ignore": 0.0,
    },
}
```

### Интеграция в Runtime Loop

Learning вызывается периодически (примерно раз в 50-100 тиков):

```python
if self_state.ticks % learning_interval == 0:
    statistics = learning_engine.process_statistics(self_state.memory)
    new_params = learning_engine.adjust_parameters(
        statistics, self_state.learning_params
    )
    if new_params:
        learning_engine.record_changes(
            self_state.learning_params, new_params, self_state
        )
```

## Примеры использования

### Пример 1: Изменение чувствительности к событиям

Если событие `noise` часто встречается в Memory (>20% всех событий), Learning медленно увеличивает чувствительность к этому типу событий (макс. +0.01).

**БЕЗ оценки эффективности**, только на основе частоты.

### Пример 2: Изменение порогов значимости

Если средняя значимость событий типа `shock` высокая (>0.5), Learning медленно снижает порог значимости для этого типа (макс. -0.01).

**БЕЗ оценки эффективности**, только на основе статистики.

### Пример 3: Изменение коэффициентов реакции

Если паттерн `dampen` часто используется (>30% всех паттернов), Learning медленно увеличивает коэффициент реакции для этого паттерна (макс. +0.01).

**БЕЗ оценки эффективности**, только на основе частоты использования.

## Тестирование

### Unit тесты

- `test_process_statistics_*` — проверка извлечения статистики
- `test_adjust_parameters_*` — проверка медленного изменения параметров
- `test_record_changes_*` — проверка фиксации изменений
- `test_no_optimization_methods` — проверка отсутствия запрещенных методов
- `test_no_goals_or_rewards` — проверка отсутствия целей и reward

### Интеграционные тесты

- `test_learning_with_feedback_data` — интеграция с Feedback
- `test_learning_frequency_in_runtime` — частота вызова в runtime loop
- `test_learning_persistence_in_snapshots` — сохранение в snapshots

### Статические тесты

- `test_forbidden_methods_comprehensive` — проверка отсутствия запрещенных методов
- `test_source_code_analysis` — анализ исходного кода на запрещенные паттерны

## Взаимодействие с другими компонентами

### Memory

Learning использует Memory как источник статистики:
- Читает записи Memory для анализа частоты событий
- Использует Feedback данные из Memory для анализа паттернов действий
- **НЕ изменяет** Memory напрямую

### Feedback

Learning использует Feedback данные из Memory:
- Анализирует паттерны действий (`action_pattern`)
- Анализирует изменения состояния (`state_delta`)
- **НЕ инициирует** Feedback

### SelfState

Learning обновляет `self_state.learning_params`:
- Медленно изменяет параметры (<= 0.01 за раз)
- Сохраняет параметры в snapshots
- **НЕ изменяет** другие поля SelfState (energy, stability, integrity)

**ВАЖНО:** Параметры сохраняются и активно используются другими компонентами (MeaningEngine, Decision, Action).

## Контрольное правило

> **Learning не отвечает на вопрос "что делать дальше".**

Он отвечает только на вопрос:

> **"изменились ли внутренние параметры"**

И даже это без интерпретации.

## Архитектурный стоп-сигнал

Если при развитии Learning появляется ощущение, что:
- Life «учится улучшать себя»
- Life «стремится к цели»
- Life «оптимизирует решения»

→ развитие слоя Learning **немедленно останавливается**.

Learning — не воля.  
Learning — не оптимизация.  
Learning — медленное внутреннее изменение без цели.

## Документация ограничений

Подробные архитектурные ограничения описаны в:
- [Learning Limits](../concepts/learning.md) — концептуальные ограничения
- [Learning Concept](../concepts/learning.md) — концепция Learning

## История

- **2026-01-26:** Реализован Learning Engine (v1.0)
- **2026-01-26:** Добавлены тесты (unit, integration, static)
- **2026-01-26:** Интегрирован в Runtime Loop
- **2026-01-19:** Исправлены критические проблемы:
  - Исправлена логика merge параметров в `record_changes()` (вместо полной перезаписи)
  - Заменен assert на явную проверку с ValueError
  - Вынесены магические числа в константы с понятными именами
  - Исправлены импорты на абсолютные
  - Добавлена обработка отсутствующих параметров с логированием
  - Добавлен тест на частичное обновление параметров
  - Обновлена документация с указанием ограничений использования параметров
- **2026-01-26:** Интегрированы параметры в систему:
  - Параметры `learning_params` теперь используются в MeaningEngine, Decision и Action
  - Добавлены тесты на использование параметров при деградации
  - Добавлены тесты на восстановление параметров из snapshot
  - Обновлена документация с описанием интеграции
