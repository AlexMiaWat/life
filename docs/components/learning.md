# 14 — Learning Engine

## Назначение

Learning Engine — это механизм медленного изменения внутренних параметров Life без оптимизации, целей или оценки эффективности.

**ВАЖНО:** Learning НЕ является:
- ❌ Оптимизацией или reinforcement learning
- ❌ Управлением поведением
- ❌ Системой с целями и намерениями
- ❌ Оценкой эффективности действий

Learning — это только **медленное изменение внутренних параметров** на основе статистики из Memory.

## Текущий статус

✅ **Реализован** (v1.0, Этап 14)
*   Файл: [`src/learning/learning.py`](../../src/learning/learning.py)
*   Интегрирован в Runtime Loop
*   Протестирован: [`src/test/test_learning.py`](../../src/test/test_learning.py)
*   Критические исправления: [`src/test/test_critical_fixes.py`](../../src/test/test_critical_fixes.py)

### Критические исправления (task_1768908574)

#### Исправление race condition в `record_changes()`

**Проблема:** При параллельных вызовах `record_changes()` существовала возможность потери данных из-за изменения словаря, который мог быть использован другим потоком.

**Решение:** Использование `copy.deepcopy()` для создания полностью независимой копии параметров перед обновлением. Все операции обновления выполняются на копии, а затем атомарно заменяются в `self_state.learning_params`.

**Код:**
```python
# Создаем глубокую копию текущих параметров для безопасного обновления
updated_params = copy.deepcopy(self_state.learning_params)

# Обновляем копию
for key, new_value_dict in new_params.items():
    # ... обновление ...

# Атомарно заменяем все параметры одной операцией
self_state.learning_params = updated_params
```

**Тесты:** Добавлены тесты в `test_critical_fixes.py` для проверки параллельных вызовов и отсутствия потери данных.

#### Улучшение типобезопасности

**Изменение:** Добавлены type hints для параметра `self_state` в методе `record_changes()`:
```python
def record_changes(
    self, old_params: Dict, new_params: Dict, self_state: "SelfState"
) -> None:
```

#### Константы

Все константы Learning Engine определены в модуле и имеют документацию с обоснованием выбора значений:
- `MAX_PARAMETER_DELTA = 0.01` - максимальное изменение параметра за один вызов
- `MIN_PARAMETER_DELTA = 0.001` - минимальное изменение для применения
- `_VALIDATION_TOLERANCE = 0.001` - допуск для проверки изменений параметров

### ✅ Интеграция параметров

**Параметры Learning теперь используются в системе:**

Параметры `learning_params` (event_type_sensitivity, significance_thresholds, response_coefficients) изменяются Learning Engine и **активно применяются** в:
- ✅ MeaningEngine (интерпретация событий) - `appraisal()`, `response_pattern()`, `process()`
- ✅ Decision Engine (выбор паттернов реакции) - `decide_response()`
- ✅ Action Engine (выполнение действий) - `execute_action()`

**Как используются параметры:**

1. **`event_type_sensitivity`** - используется в `MeaningEngine.appraisal()` для модификации значимости событий на основе обученной чувствительности
2. **`significance_thresholds`** - используется в `MeaningEngine.response_pattern()` и `Decision.decide_response()` для определения порогов значимости
3. **`response_coefficients`** - используется в `MeaningEngine.process()` и `Action.execute_action()` для модификации коэффициентов реакции

**Интеграция с Adaptation:**
- Параметры Learning используются Adaptation Manager для медленной перестройки поведения
- Adaptation создает `adaptation_params` на основе `learning_params`
- Оба набора параметров используются в системе для влияния на поведение

**Статус:** Параметры полностью интегрированы и влияют на поведение системы.

### Детальное описание влияния параметров на поведение

#### 1. `event_type_sensitivity` - Влияние на значимость событий

**Где используется:** `MeaningEngine.appraisal()`

**Как работает:**
- Значение параметра в диапазоне [0.0, 1.0] преобразуется в модификатор [0.5, 1.0]
- Модификатор применяется к значимости события через среднее значение с `behavior_sensitivity`
- Высокое значение (близко к 1.0) → событие становится более значимым (макс. 1.5x)
- Низкое значение (близко к 0.0) → событие становится менее значимым (мин. 0.5x)

**Пример:**
- `event_type_sensitivity["shock"] = 0.8` → модификатор ≈ 0.9 → значимость увеличивается
- `event_type_sensitivity["noise"] = 0.2` → модификатор ≈ 0.6 → значимость уменьшается

**Ограничение:** Максимальное изменение значимости ограничено 1.5x для соблюдения принципа медленного изменения.

#### 2. `significance_thresholds` - Влияние на пороги игнорирования

**Где используется:** `MeaningEngine.response_pattern()`, `Decision.decide_response()`

**Как работает:**
- Определяет минимальную значимость события для его обработки
- Если значимость события < порога → событие игнорируется (`ignore` паттерн)
- Высокий порог → больше событий игнорируется
- Низкий порог → меньше событий игнорируется

**Пример:**
- `significance_thresholds["noise"] = 0.3` → события noise с значимостью < 0.3 игнорируются
- `significance_thresholds["shock"] = 0.1` → события shock почти всегда обрабатываются

#### 3. `response_coefficients` - Влияние на эффекты действий

**Где используется:** `MeaningEngine.process()`, `Action.execute_action()`

**Как работает:**
- Определяет коэффициент модификации эффектов паттернов реакции
- Применяется к `impact` событий при обработке паттернов (`dampen`, `absorb`, `amplify`)
- Высокий коэффициент → эффект усиливается
- Низкий коэффициент → эффект ослабляется

**Пример:**
- `response_coefficients["dampen"] = 0.3` → эффект dampen уменьшается в 0.3 раза
- `response_coefficients["absorb"] = 1.2` → эффект absorb увеличивается в 1.2 раза

**Приоритет:** `adaptation_params.behavior_coefficients` имеет приоритет над `learning_params.response_coefficients`.

## Архитектурные ограничения

### Абсолютные запреты

1. **Запрет на оптимизацию**
   - ❌ Не усиливает или ослабляет действия
   - ❌ Не выбирает лучший вариант
   - ❌ Не корректирует поведение

2. **Запрет на цели и намерения**
   - ❌ Не работает для достижения цели
   - ❌ Не направлено на результат
   - ❌ Не имеет reward/punishment

3. **Запрет на циклы обратной связи**
   - ❌ Не использует Decision → Action → Feedback как цикл контроля
   - ❌ Не инициирует новые действия
   - ❌ Не корректирует будущие действия напрямую

4. **Запрет на внешнюю зависимость**
   - ❌ Не требует внешних метрик
   - ❌ Не взаимодействует с KPI или success metrics

### Разрешённый минимум

Learning **может**:
- ✅ Постепенно изменять внутренние параметры (макс. 0.01 за раз)
- ✅ Фиксировать изменения без интерпретации
- ✅ Использовать внутреннюю статистику из Memory

Learning **не может**:
- ❌ Оценивать правильность изменений
- ❌ Вмешиваться в Decision или Action
- ❌ Инициировать Feedback

## Реализация

### Основные методы

#### `process_statistics(memory: List[MemoryEntry]) -> Dict`

Анализирует Memory для извлечения статистики:
- Типы событий и их частота
- Паттерны действий из Feedback
- Изменения состояния из Feedback

**ВАЖНО:** Без интерпретации, только сбор статистики.

#### `adjust_parameters(statistics: Dict, current_params: Dict) -> Dict`

Медленно изменяет внутренние параметры на основе статистики:
- Изменение чувствительности к типам событий (`event_type_sensitivity`)
- Изменение порогов значимости (`significance_thresholds`)
- Изменение коэффициентов реакции (`response_coefficients`)

**Ограничения:**
- Максимальное изменение: `MAX_PARAMETER_DELTA = 0.01` за раз
- Минимальное изменение: `MIN_PARAMETER_DELTA = 0.001` (чтобы избежать микро-изменений)
- Изменения основаны на частоте/паттернах, НЕ на оценке эффективности

#### `record_changes(old_params: Dict, new_params: Dict, self_state: SelfState) -> None`

Фиксирует изменения параметров в SelfState без интерпретации.

**Проверки:**
- Убеждается, что изменения медленные (<= 0.01)
- Обновляет `self_state.learning_params`
- Не сохраняет историю изменений, не интерпретирует, не оценивает

### Параметры Learning

Параметры хранятся в `SelfState.learning_params`:

```python
learning_params = {
    "event_type_sensitivity": {
        "noise": 0.2,
        "decay": 0.2,
        "recovery": 0.2,
        "shock": 0.2,
        "idle": 0.2,
    },
    "significance_thresholds": {
        "noise": 0.1,
        "decay": 0.1,
        "recovery": 0.1,
        "shock": 0.1,
        "idle": 0.1,
    },
    "response_coefficients": {
        "dampen": 0.5,
        "absorb": 1.0,
        "ignore": 0.0,
    },
}
```

### Интеграция в Runtime Loop

Learning вызывается периодически (примерно раз в 50-100 тиков):

```python
if self_state.ticks % learning_interval == 0:
    statistics = learning_engine.process_statistics(self_state.memory)
    new_params = learning_engine.adjust_parameters(
        statistics, self_state.learning_params
    )
    if new_params:
        learning_engine.record_changes(
            self_state.learning_params, new_params, self_state
        )
```

## Примеры использования

### Пример 1: Изменение чувствительности к событиям

Если событие `noise` часто встречается в Memory (>20% всех событий), Learning медленно увеличивает чувствительность к этому типу событий (макс. +0.01).

**БЕЗ оценки эффективности**, только на основе частоты.

### Пример 2: Изменение порогов значимости

Если средняя значимость событий типа `shock` высокая (>0.5), Learning медленно снижает порог значимости для этого типа (макс. -0.01).

**БЕЗ оценки эффективности**, только на основе статистики.

### Пример 3: Изменение коэффициентов реакции

Если паттерн `dampen` часто используется (>30% всех паттернов), Learning медленно увеличивает коэффициент реакции для этого паттерна (макс. +0.01).

**БЕЗ оценки эффективности**, только на основе частоты использования.

## Тестирование

### Unit тесты

- `test_process_statistics_*` — проверка извлечения статистики
- `test_adjust_parameters_*` — проверка медленного изменения параметров
- `test_record_changes_*` — проверка фиксации изменений
- `test_no_optimization_methods` — проверка отсутствия запрещенных методов
- `test_no_goals_or_rewards` — проверка отсутствия целей и reward

### Интеграционные тесты

- `test_learning_with_feedback_data` — интеграция с Feedback
- `test_learning_frequency_in_runtime` — частота вызова в runtime loop
- `test_learning_persistence_in_snapshots` — сохранение в snapshots

### Статические тесты

- `test_forbidden_methods_comprehensive` — проверка отсутствия запрещенных методов
- `test_source_code_analysis` — анализ исходного кода на запрещенные паттерны

## Взаимодействие с другими компонентами

### Memory

Learning использует Memory как источник статистики:
- Читает записи Memory для анализа частоты событий
- Использует Feedback данные из Memory для анализа паттернов действий
- **НЕ изменяет** Memory напрямую

### Feedback

Learning использует Feedback данные из Memory:
- Анализирует паттерны действий (`action_pattern`)
- Анализирует изменения состояния (`state_delta`)
- **НЕ инициирует** Feedback

### SelfState

Learning обновляет `self_state.learning_params`:
- Медленно изменяет параметры (<= 0.01 за раз)
- Сохраняет параметры в snapshots
- **НЕ изменяет** другие поля SelfState (energy, stability, integrity)

**ВАЖНО:** Параметры сохраняются и активно используются другими компонентами (MeaningEngine, Decision, Action).

## Контрольное правило

> **Learning не отвечает на вопрос "что делать дальше".**

Он отвечает только на вопрос:

> **"изменились ли внутренние параметры"**

И даже это без интерпретации.

## Архитектурный стоп-сигнал

Если при развитии Learning появляется ощущение, что:
- Life «учится улучшать себя»
- Life «стремится к цели»
- Life «оптимизирует решения»

→ развитие слоя Learning **немедленно останавливается**.

Learning — не воля.
Learning — не оптимизация.
Learning — медленное внутреннее изменение без цели.

## Документация ограничений

Подробные архитектурные ограничения описаны в:
- [Learning Limits](../concepts/learning.md) — концептуальные ограничения
- [Learning Concept](../concepts/learning.md) — концепция Learning

## История

- **2026-01-26:** Реализован Learning Engine (v1.0)
- **2026-01-26:** Добавлены тесты (unit, integration, static)
- **2026-01-26:** Интегрирован в Runtime Loop
- **2026-01-19:** Исправлены критические проблемы:
  - Исправлена логика merge параметров в `record_changes()` (вместо полной перезаписи)
  - Заменен assert на явную проверку с ValueError
  - Вынесены магические числа в константы с понятными именами
  - Исправлены импорты на абсолютные
  - Добавлена обработка отсутствующих параметров с логированием
  - Добавлен тест на частичное обновление параметров
  - Обновлена документация с указанием ограничений использования параметров
- **2026-01-26:** Интегрированы параметры в систему:
  - Параметры `learning_params` теперь используются в MeaningEngine, Decision и Action
  - Добавлены тесты на использование параметров при деградации
  - Добавлены тесты на восстановление параметров из snapshot
  - Обновлена документация с описанием интеграции
