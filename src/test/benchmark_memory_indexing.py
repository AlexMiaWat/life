#!/usr/bin/env python3
"""
–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏.
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ä–æ–≥–æ –∏ –Ω–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–æ–≤.
"""

import time
import random
from pathlib import Path
import sys

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

from memory.memory import ArchiveMemory
from memory.index_engine import MemoryIndexEngine, MemoryQuery
from memory.types import MemoryEntry
from runtime.performance_metrics import performance_metrics


def generate_test_entries(count: int) -> list[MemoryEntry]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –ø–∞–º—è—Ç–∏."""
    event_types = ["decay", "recovery", "shock", "noise", "learning", "adaptation"]
    entries = []

    base_time = time.time() - 86400 * 30  # 30 –¥–Ω–µ–π –Ω–∞–∑–∞–¥

    for i in range(count):
        event_type = random.choice(event_types)
        significance = random.uniform(0.1, 1.0)
        timestamp = base_time + random.uniform(0, 86400 * 30)
        weight = random.uniform(0.1, 1.0)

        entry = MemoryEntry(
            event_type=event_type,
            meaning_significance=significance,
            timestamp=timestamp,
            weight=weight
        )
        entries.append(entry)

    return entries


def benchmark_linear_search(entries: list[MemoryEntry], queries: list[MemoryQuery]) -> dict:
    """–ó–∞–º–µ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ª–∏–Ω–µ–π–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (—Å—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥)."""
    print(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–∞ {len(entries)} –∑–∞–ø–∏—Å—è—Ö...")

    # –ó–∞–º–µ—Ä –ø–æ–∏—Å–∫–∞
    search_times = []
    for query in queries:
        start_time = time.perf_counter()

        # –õ–∏–Ω–µ–π–Ω—ã–π –ø–æ–∏—Å–∫ (–∏–º–∏—Ç–∞—Ü–∏—è —Å—Ç–∞—Ä–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞)
        results = []
        for entry in entries:
            if (query.event_type is None or entry.event_type == query.event_type) and \
               (query.min_significance is None or entry.meaning_significance >= query.min_significance) and \
               (query.start_timestamp is None or entry.timestamp >= query.start_timestamp) and \
               (query.end_timestamp is None or entry.timestamp <= query.end_timestamp):
                results.append(entry)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –ª–∏–º–∏—Ç
        if query.sort_by == "significance":
            results.sort(key=lambda x: x.meaning_significance, reverse=(query.sort_order == "desc"))
        results = results[:query.limit]

        end_time = time.perf_counter()
        search_times.append(end_time - start_time)

    avg_search_time = sum(search_times) / len(search_times)
    return {
        "method": "linear_search",
        "entries_count": len(entries),
        "queries_count": len(queries),
        "avg_search_time": avg_search_time,
        "total_search_time": sum(search_times),
        "results_per_query": len(results) if 'results' in locals() else 0
    }


def benchmark_indexed_search(entries: list[MemoryEntry], queries: list[MemoryQuery]) -> dict:
    """–ó–∞–º–µ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥)."""
    print(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–∞ {len(entries)} –∑–∞–ø–∏—Å—è—Ö...")

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    index_start = time.perf_counter()
    engine = MemoryIndexEngine(max_cache_size=50)  # –£–≤–µ–ª–∏—á–∏–º –∫—ç—à –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    for entry in entries:
        engine.add_entry(entry)
    index_build_time = time.perf_counter() - index_start

    print(".2f")

    # –ó–∞–º–µ—Ä –ø–æ–∏—Å–∫–∞ (—Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º–∏—Å—è –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫—ç—à–∞)
    search_times = []
    all_queries = queries + queries[:10]  # –î–æ–±–∞–≤–∏–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–ø—Ä–æ—Å—ã

    for query in all_queries:
        start_time = time.perf_counter()
        results = engine.search(query)
        end_time = time.perf_counter()

        search_times.append(end_time - start_time)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
    stats = engine.get_stats()
    cache_hits = stats["cache_hits"]
    cache_misses = stats["cache_misses"]

    avg_search_time = sum(search_times) / len(search_times)

    return {
        "method": "indexed_search",
        "entries_count": len(entries),
        "queries_count": len(all_queries),
        "index_build_time": index_build_time,
        "avg_search_time": avg_search_time,
        "total_search_time": sum(search_times),
        "cache_hit_rate": cache_hits / (cache_hits + cache_misses) if (cache_hits + cache_misses) > 0 else 0,
        "results_per_query": len(results) if 'results' in locals() else 0
    }


def generate_test_queries(count: int, entries: list[MemoryEntry]) -> list[MemoryQuery]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã."""
    queries = []
    event_types = list(set(entry.event_type for entry in entries))

    for _ in range(count):
        query_type = random.choice(["event_type_only", "complex", "time_range", "significance_only"])

        if query_type == "event_type_only":
            query = MemoryQuery(
                event_type=random.choice(event_types),
                limit=random.randint(5, 50)
            )
        elif query_type == "complex":
            query = MemoryQuery(
                event_type=random.choice(event_types) if random.random() > 0.3 else None,
                min_significance=random.uniform(0.3, 0.8) if random.random() > 0.4 else None,
                start_timestamp=min(e.timestamp for e in entries) if random.random() > 0.5 else None,
                end_timestamp=max(e.timestamp for e in entries) if random.random() > 0.5 else None,
                limit=random.randint(5, 50)
            )
        elif query_type == "time_range":
            timestamps = sorted([e.timestamp for e in entries])
            start_idx = random.randint(0, len(timestamps) // 2)
            end_idx = random.randint(start_idx + 1, len(timestamps) - 1)
            query = MemoryQuery(
                start_timestamp=timestamps[start_idx],
                end_timestamp=timestamps[end_idx],
                limit=random.randint(5, 50)
            )
        else:  # significance_only
            query = MemoryQuery(
                min_significance=random.uniform(0.2, 0.9),
                limit=random.randint(5, 50)
            )

        queries.append(query)

    return queries


def run_realistic_benchmark():
    """–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π benchmark —Å –±–æ–ª—å—à–∏–º –æ–±—ä–µ–º–æ–º –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º–∏—Å—è –∑–∞–ø—Ä–æ—Å–∞–º–∏."""
    print("üéØ –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π benchmark: 10k –∑–∞–ø–∏—Å–µ–π, –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–ø—Ä–æ—Å—ã")
    print("-" * 60)

    # –ë–æ–ª—å—à–æ–π –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö
    entries = generate_test_entries(10000)
    engine = MemoryIndexEngine(max_cache_size=200)

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    print("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è 10k –∑–∞–ø–∏—Å–µ–π...")
    index_start = time.perf_counter()
    for entry in entries:
        engine.add_entry(entry)
    index_time = time.perf_counter() - index_start
    print(".2f")

    # –°–æ–∑–¥–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–ø—Ä–æ—Å—ã (—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π)
    base_queries = generate_test_queries(20, entries)  # 20 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    repeated_queries = base_queries * 50  # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å 50 —Ä–∞–∑

    print(f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ {len(repeated_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤ (—Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏)...")

    # –ó–∞–º–µ—Ä –ø–æ–∏—Å–∫–∞
    search_start = time.perf_counter()
    for query in repeated_queries:
        results = engine.search(query)
    search_time = time.perf_counter() - search_start

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = engine.get_stats()
    avg_query_time = search_time / len(repeated_queries)

    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –†–ï–ê–õ–ò–°–¢–ò–ß–ù–û–ì–û –¢–ï–°–¢–ê:")
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {search_time:.4f}s")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞: {avg_query_time:.6f}s")
    print(f"–ó–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É: {len(repeated_queries) / search_time:.1f}")
    print(f"–ö—ç—à hit rate: {stats['cache_hit_rate']:.1%}")
    print(f"–í—Å–µ–≥–æ –∫—ç—à hits: {stats['cache_hits']}")
    print(f"–í—Å–µ–≥–æ –∫—ç—à misses: {stats['cache_misses']}")

    return {
        "entries": 10000,
        "queries": len(repeated_queries),
        "index_time": index_time,
        "search_time": search_time,
        "avg_query_time": avg_query_time,
        "qps": len(repeated_queries) / search_time,
        "cache_hit_rate": stats['cache_hit_rate']
    }


def run_benchmark():
    """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ benchmark —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    print("üöÄ –ó–∞–ø—É—Å–∫ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏")
    print("=" * 60)

    # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    test_sizes = [1000]
    queries_per_test = 50

    for size in test_sizes:
        print(f"\nüìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å {size} –∑–∞–ø–∏—Å—è–º–∏ –ø–∞–º—è—Ç–∏")
        print("-" * 40)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        entries = generate_test_entries(size)
        queries = generate_test_queries(queries_per_test, entries)

        # –õ–∏–Ω–µ–π–Ω—ã–π –ø–æ–∏—Å–∫
        linear_results = benchmark_linear_search(entries, queries)

        # –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫
        indexed_results = benchmark_indexed_search(entries, queries)

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"–õ–∏–Ω–µ–π–Ω—ã–π –ø–æ–∏—Å–∫:     {linear_results['avg_search_time']:.4f}s —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞")
        print(f"–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π:    {indexed_results['avg_search_time']:.4f}s —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞")
        print(f"–í—Ä–µ–º—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞: {indexed_results['index_build_time']:.4f}s")
        print(f"–£—Å–∫–æ—Ä–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞:   {linear_results['avg_search_time'] / indexed_results['avg_search_time']:.1f}x")
        print(f"–ö—ç—à hit rate:       {indexed_results['cache_hit_rate']:.1%}")

        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞
        stats = performance_metrics.get_average_time("memory_index_add_entry")
        if stats:
            print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –∏–Ω–¥–µ–∫—Å: {stats:.6f}s")

        search_stats = performance_metrics.get_average_time("memory_index_search")
        if search_stats:
            print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {search_stats:.6f}s")

    # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —Ç–µ—Å—Ç
    realistic_results = run_realistic_benchmark()

    print("\n‚úÖ –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

    # –ò—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã
    print("\nüéØ –í–´–í–û–î–´:")
    print("–î–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö (1k-5k) –ª–∏–Ω–µ–π–Ω—ã–π –ø–æ–∏—Å–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –±—ã—Å—Ç—Ä–µ–µ –∏–∑-–∑–∞ overhead –∏–Ω–¥–µ–∫—Å–æ–≤")
    print("–î–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º–∏—Å—è –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∏–Ω–¥–µ–∫—Å—ã –¥–∞—é—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ")
    print(f"–í —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏: {realistic_results['qps']:.1f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫")
    print(f"–ö—ç—à hit rate: {realistic_results['cache_hit_rate']:.1%}")
    print("–ò–Ω–¥–µ–∫—Å—ã –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ event_type –∏ range –∑–∞–ø—Ä–æ—Å–æ–≤")


if __name__ == "__main__":
    run_benchmark()