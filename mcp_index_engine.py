#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è MCP —Å–µ—Ä–≤–µ—Ä–∞.
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–æ–≤ –∏ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞.
"""

import logging
import re
from collections import OrderedDict
from pathlib import Path
from typing import Optional

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DEFAULT_SEARCH_LIMIT = 10
DEFAULT_CACHE_SIZE_LIMIT = 10000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –∫—ç—à–µ
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10 MB - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏


class IndexEngine:
    """
    –î–≤–∏–∂–æ–∫ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ —Ñ–∞–π–ª–∞–º.

    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:
    - –ö—ç—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–æ–≤ (content_cache)
    - –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å (inverted_index) –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ —Ç–æ–∫–µ–Ω–∞–º
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤
    """

    def __init__(
        self,
        docs_dir: Path,
        todo_dir: Path,
        src_dir: Path,
        cache_size_limit: int = DEFAULT_CACHE_SIZE_LIMIT,
        max_file_size: int = MAX_FILE_SIZE,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è IndexEngine.

        Args:
            docs_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π
            todo_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å TODO —Ñ–∞–π–ª–∞–º–∏
            src_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º
            cache_size_limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –∫—ç—à–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10000)
            max_file_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ –±–∞–π—Ç–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10MB)
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not isinstance(docs_dir, Path):
            docs_dir = Path(docs_dir)
        if not isinstance(todo_dir, Path):
            todo_dir = Path(todo_dir)
        if not isinstance(src_dir, Path):
            src_dir = Path(src_dir)

        self.docs_dir = docs_dir.resolve()
        self.todo_dir = todo_dir.resolve()
        self.src_dir = src_dir.resolve()
        self.cache_size_limit = cache_size_limit
        self.max_file_size = max_file_size

        # –ö—ç—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–æ–≤: –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å -> —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º OrderedDict –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ LRU eviction
        self.content_cache: OrderedDict[str, str] = OrderedDict()

        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å: —Ç–æ–∫–µ–Ω -> –º–Ω–æ–∂–µ—Å—Ç–≤–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
        self.inverted_index: dict[str, set[str]] = {}

        # –í—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤: –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å -> mtime
        self.file_mtimes: dict[str, float] = {}

        # –ò–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ —Ç–æ–∫–µ–Ω–∞–º (–¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è)
        # –§–∞–π–ª -> –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
        self.file_tokens: dict[str, set[str]] = {}

        # –§–ª–∞–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self._initialized = False

        # –ö—ç—à —Å—Ç–∞—Ç—É—Å–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å -> —Å—Ç–∞—Ç—É—Å
        self._document_status_cache: dict[str, str] = {}
        
        # –í—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ —Å—Ç–∞—Ç—É—Å–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
        self._status_file_mtime: Optional[float] = None

    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)."""
        if not self._initialized:
            self.index_directory(self.docs_dir, "*.md")
            self.index_directory(self.todo_dir, "*.md")
            self._initialized = True

    def _tokenize_content(self, content: str) -> set[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞.

        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞

        Returns:
            –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (—Å–ª–æ–≤) –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        """
        tokens = re.findall(r"\b\w+\b", content.lower())
        return set(tokens)

    def _load_content(self, file_path: Path) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–∞–∑–º–µ—Ä–∞.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞

        Raises:
            ValueError: –ï—Å–ª–∏ —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
            IOError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        file_size = file_path.stat().st_size
        if file_size > self.max_file_size:
            raise ValueError(
                f"–§–∞–π–ª {file_path} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size} –±–∞–π—Ç). "
                f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {self.max_file_size} –±–∞–π—Ç"
            )

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
            raise

    def _validate_path(self, file_path: Path, base_dir: Path) -> bool:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –ø—É—Ç—å —Ñ–∞–π–ª–∞ –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç path traversal.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è

        Returns:
            True –µ—Å–ª–∏ –ø—É—Ç—å –≤–∞–ª–∏–¥–µ–Ω, False –∏–Ω–∞—á–µ
        """
        try:
            resolved_path = file_path.resolve()
            resolved_base = base_dir.resolve()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            return (
                resolved_base in resolved_path.parents
                or resolved_path.parent == resolved_base
            )
        except Exception:
            return False

    def _get_base_dir(self, file_path: Path) -> Optional[Path]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –±–∞–∑–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ñ–∞–π–ª–∞.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∏–ª–∏ None
        """
        try:
            resolved_path = file_path.resolve()
            if (
                self.docs_dir in resolved_path.parents
                or resolved_path.parent == self.docs_dir
            ):
                return self.docs_dir
            elif (
                self.todo_dir in resolved_path.parents
                or resolved_path.parent == self.todo_dir
            ):
                return self.todo_dir
            elif (
                self.src_dir in resolved_path.parents
                or resolved_path.parent == self.src_dir
            ):
                return self.src_dir
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è {file_path}: {e}")
        return None

    def _get_relative_path(self, file_path: Path, base_dir: Path) -> str:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å —Ñ–∞–π–ª–∞ –æ—Ç –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.

        Args:
            file_path: –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è

        Returns:
            –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
        """
        try:
            return str(file_path.relative_to(base_dir))
        except ValueError:
            # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
            return str(file_path)

    def _update_index_for_file(self, rel_path: str, content: str):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è —Ñ–∞–π–ª–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è).

        Args:
            rel_path: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        """
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã
        new_tokens = self._tokenize_content(content)

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ —Ñ–∞–π–ª–æ–≤
        old_tokens = self.file_tokens.get(rel_path, set())

        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–∫–µ–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        tokens_to_remove = old_tokens - new_tokens
        tokens_to_add = new_tokens - old_tokens

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        for token in tokens_to_remove:
            if token in self.inverted_index:
                self.inverted_index[token].discard(rel_path)
                if not self.inverted_index[token]:
                    del self.inverted_index[token]

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –≤ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        for token in tokens_to_add:
            if token not in self.inverted_index:
                self.inverted_index[token] = set()
            self.inverted_index[token].add(rel_path)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å —Ñ–∞–π–ª–æ–≤
        self.file_tokens[rel_path] = new_tokens

    def _evict_cache_if_needed(self):
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫—ç—à–∞, –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç (LRU eviction)."""
        while len(self.content_cache) >= self.cache_size_limit:
            # –£–¥–∞–ª—è–µ–º —Å–∞–º—É—é —Å—Ç–∞—Ä—É—é –∑–∞–ø–∏—Å—å (FIFO –∏–∑ OrderedDict)
            oldest_key = next(iter(self.content_cache))
            self._remove_file_from_cache(oldest_key)

    def _remove_file_from_cache(self, rel_path: str):
        """
        –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏–∑ –∫—ç—à–∞ –∏ –∏–Ω–¥–µ–∫—Å–æ–≤.

        Args:
            rel_path: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        """
        # –£–¥–∞–ª—è–µ–º –∏–∑ –∫—ç—à–∞
        if rel_path in self.content_cache:
            del self.content_cache[rel_path]

        # –£–¥–∞–ª—è–µ–º –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if rel_path in self.file_mtimes:
            del self.file_mtimes[rel_path]

        # –£–¥–∞–ª—è–µ–º —Ç–æ–∫–µ–Ω—ã —Ñ–∞–π–ª–∞ –∏–∑ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        if rel_path in self.file_tokens:
            tokens = self.file_tokens[rel_path]
            for token in tokens:
                if token in self.inverted_index:
                    self.inverted_index[token].discard(rel_path)
                    if not self.inverted_index[token]:
                        del self.inverted_index[token]
            del self.file_tokens[rel_path]

    def _get_content(self, file_path: Path, base_dir: Path) -> str:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑ –∫—ç—à–∞ –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç.

        Args:
            file_path: –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è

        Returns:
            –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—É—Ç–∏
        if not self._validate_path(file_path, base_dir):
            logger.warning(
                f"–ü–æ–ø—ã—Ç–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É –≤–Ω–µ –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {file_path}"
            )
            return ""

        rel_path = self._get_relative_path(file_path, base_dir)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ñ–∞–π–ª–∞
        if file_path.exists():
            try:
                current_mtime = file_path.stat().st_mtime
                if rel_path in self.file_mtimes:
                    if current_mtime > self.file_mtimes[rel_path]:
                        # –§–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è, –æ–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
                        try:
                            content = self._load_content(file_path)
                            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ –∫–æ–Ω–µ—Ü –¥–ª—è LRU (–æ–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –¥–æ—Å—Ç—É–ø–∞)
                            if rel_path in self.content_cache:
                                del self.content_cache[rel_path]
                            self.content_cache[rel_path] = content
                            self.file_mtimes[rel_path] = current_mtime
                            self._update_index_for_file(rel_path, content)
                            return content
                        except ValueError as e:
                            logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {file_path}: {e}")
                            return ""
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
                            return ""

                # –§–∞–π–ª –Ω–µ –≤ –∫—ç—à–µ –∏–ª–∏ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è
                if rel_path not in self.content_cache:
                    try:
                        content = self._load_content(file_path)
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –∫—ç—à–∞ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
                        self._evict_cache_if_needed()
                        self.content_cache[rel_path] = content
                        self.file_mtimes[rel_path] = current_mtime
                        self._update_index_for_file(rel_path, content)
                    except ValueError as e:
                        logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {file_path}: {e}")
                        return ""
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
                        return ""

                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ –∫–æ–Ω–µ—Ü –¥–ª—è LRU (–æ–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –¥–æ—Å—Ç—É–ø–∞)
                content = self.content_cache.pop(rel_path)
                self.content_cache[rel_path] = content
                return content
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É {file_path}: {e}")
                return ""
        else:
            # –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —É–¥–∞–ª—è–µ–º –∏–∑ –∫—ç—à–∞
            if rel_path in self.content_cache:
                self._remove_file_from_cache(rel_path)
            return ""

    def index_directory(self, directory: Path, file_pattern: str = "*.md"):
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.

        Args:
            directory: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            file_pattern: –ü–∞—Ç—Ç–µ—Ä–Ω —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "*.md")
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not isinstance(directory, Path):
            directory = Path(directory)

        if not directory.exists():
            logger.warning(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {directory}")
            return

        if not directory.is_dir():
            logger.warning(f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π: {directory}")
            return

        indexed_count = 0
        skipped_count = 0

        for file_path in directory.rglob(file_pattern):
            if file_path.is_file():
                try:
                    self._get_content(file_path, directory)
                    indexed_count += 1
                except Exception as e:
                    logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {file_path} –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
                    skipped_count += 1
                    continue

        logger.info(
            f"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {directory} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: "
            f"–ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count}, –ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count}"
        )

    def reindex(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—É—é –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –≤—Å–µ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π."""
        logger.info("–ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        self.content_cache.clear()
        self.inverted_index.clear()
        self.file_mtimes.clear()
        self.file_tokens.clear()
        self._initialized = False
        self.initialize()
        logger.info("–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def update_file(self, file_path: Path):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω–¥–µ–∫—Å –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not isinstance(file_path, Path):
            file_path = Path(file_path)

        base_dir = self._get_base_dir(file_path)
        if base_dir and file_path.exists():
            try:
                self._get_content(file_path, base_dir)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")

    def get_file_content(self, file_path: Path, base_dir: Path) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∏–∑ –∫—ç—à–∞.

        Args:
            file_path: –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è

        Returns:
            –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∏–ª–∏ None, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –≤ –∫—ç—à–µ
        """
        rel_path = self._get_relative_path(file_path, base_dir)
        return self.content_cache.get(rel_path)

    def _get_document_category(self, rel_path: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ –µ–≥–æ –ø—É—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ docs/.

        Args:
            rel_path: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É

        Returns:
            –ö–∞—Ç–µ–≥–æ—Ä–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: 'core', 'system', 'concepts', 'meta', 'test', 'archive' –∏–ª–∏ 'unknown'
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—É—Ç—å
        path_parts = rel_path.replace("\\", "/").split("/")
        
        if not path_parts:
            return "unknown"
        
        first_part = path_parts[0].lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –ø—É—Ç–∏
        if first_part in ("getting-started", "architecture"):
            return "core"
        elif first_part == "components":
            return "system"
        elif first_part == "concepts":
            return "concepts"
        elif first_part == "development":
            return "meta"
        elif first_part == "testing":
            return "test"
        elif first_part == "archive":
            return "archive"
        else:
            return "unknown"

    def _load_document_statuses(self) -> dict[str, str]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞—Ç—É—Å—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ docs/development/status.md.

        Returns:
            –°–ª–æ–≤–∞—Ä—å: –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞ -> —Å—Ç–∞—Ç—É—Å (‚úÖ, üß±, ‚è∏, üö´, üîÆ)
        """
        status_file = self.docs_dir / "development" / "status.md"
        
        if not status_file.exists():
            logger.debug(f"–§–∞–π–ª —Å—Ç–∞—Ç—É—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {status_file}")
            return {}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞
        try:
            current_mtime = status_file.stat().st_mtime
            if (
                self._status_file_mtime is not None
                and current_mtime <= self._status_file_mtime
                and self._document_status_cache
            ):
                # –ö—ç—à –∞–∫—Ç—É–∞–ª–µ–Ω
                return self._document_status_cache
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—É—Å–æ–≤: {e}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–∞—Ä—Å–∏–º —Ñ–∞–π–ª —Å—Ç–∞—Ç—É—Å–æ–≤
        statuses = {}
        try:
            with open(status_file, "r", encoding="utf-8") as f:
                content = f.read()
            
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
            # * **Status:** ‚úÖ Implemented
            # * **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** [filename.md](../path/to/filename.md)
            lines = content.split("\n")
            current_status = None
            
            for i, line in enumerate(lines):
                # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "* **Status:** ‚úÖ ..."
                status_match = re.search(r"\*\s+\*\*Status:\*\*\s+([‚úÖüß±‚è∏üö´üîÆ])", line)
                if status_match:
                    current_status = status_match.group(1)
                    continue
                
                # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ "* **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** [filename.md](../path/to/filename.md)"
                if current_status:
                    link_match = re.search(
                        r"\*\s+\*\*–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:\*\*\s+\[([^\]]+\.md)\]\(\.\./([^)]+)\)", line
                    )
                    if link_match:
                        doc_name = link_match.group(1)
                        doc_path = link_match.group(2)
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—É—Ç—å
                        normalized_path = doc_path.replace("\\", "/")
                        statuses[normalized_path] = current_status
                        # –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
                        statuses[doc_name] = current_status
                        current_status = None
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
            self._document_status_cache = statuses
            self._status_file_mtime = current_mtime
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç—É—Å–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        
        return statuses

    def _get_document_status(self, rel_path: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ status.md.

        Args:
            rel_path: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É

        Returns:
            –°—Ç–∞—Ç—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞: ‚úÖ, üß±, ‚è∏, üö´, üîÆ –∏–ª–∏ 'unknown'
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç—É—Å—ã (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
        statuses = self._load_document_statuses()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—É—Ç—å –¥–ª—è –ø–æ–∏—Å–∫–∞
        normalized_path = rel_path.replace("\\", "/")
        
        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        if normalized_path in statuses:
            return statuses[normalized_path]
        
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        path_parts = normalized_path.split("/")
        if path_parts:
            filename = path_parts[-1]
            for doc_path, status in statuses.items():
                if doc_path.endswith(filename):
                    return status
        
        return "unknown"

    def _calculate_document_score(self, rel_path: str) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Å—Ç–∞—Ç—É—Å–∞.

        Args:
            rel_path: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É

        Returns:
            –ß–∏—Å–ª–æ–≤–æ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (score) –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_priorities = {
            "core": 100,
            "system": 90,
            "meta": 80,
            "concepts": 60,
            "test": 50,
            "archive": 20,
            "unknown": 50,
        }
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
        status_priorities = {
            "‚úÖ": 100,  # Implemented
            "üß±": 80,   # Documented
            "üîÆ": 40,   # Future
            "‚è∏": 30,   # Blocked
            "üö´": 20,   # Forbidden
            "unknown": 50,
        }
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ —Å—Ç–∞—Ç—É—Å
        category = self._get_document_category(rel_path)
        status = self._get_document_status(rel_path)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã
        category_priority = category_priorities.get(category, 50)
        status_priority = status_priorities.get(status, 50)
        
        # –í—ã—á–∏—Å–ª—è–µ–º score –ø–æ —Ñ–æ—Ä–º—É–ª–µ: (category_priority * 0.6) + (status_priority * 0.4)
        score = (category_priority * 0.6) + (status_priority * 0.4)
        
        return score

    def _apply_search_mode(
        self,
        content: str,
        mode: str,
        tokens_or_phrase: list[str] | str,
        search_and_func,
        search_or_func,
        search_phrase_func,
    ) -> bool:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –∫ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.

        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            mode: –†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ ("AND", "OR", "PHRASE")
            tokens_or_phrase: –¢–æ–∫–µ–Ω—ã –∏–ª–∏ —Ñ—Ä–∞–∑–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            search_and_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ AND
            search_or_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ OR
            search_phrase_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ PHRASE

        Returns:
            True –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, False –∏–Ω–∞—á–µ
        """
        if mode == "PHRASE":
            return search_phrase_func(content, str(tokens_or_phrase))
        elif mode == "AND" and isinstance(tokens_or_phrase, list):
            return search_and_func(content, tokens_or_phrase)
        elif mode == "OR" and isinstance(tokens_or_phrase, list):
            return search_or_func(content, tokens_or_phrase)
        return False

    def _is_index_available(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞.

        Returns:
            True –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –¥–æ—Å—Ç—É–ø–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é, False –∏–Ω–∞—á–µ
        """
        try:
            return (
                self._initialized
                and self.inverted_index is not None
                and len(self.inverted_index) > 0
                and len(self.content_cache) > 0
            )
        except (AttributeError, TypeError):
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞—è –∫–æ–≥–¥–∞ –∏–Ω–¥–µ–∫—Å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –∏–ª–∏ None
            return False

    def _linear_search_in_cache(
        self,
        directory: Path,
        query: str,
        mode: str,
        tokens_or_phrase: list[str] | str,
        limit: int,
        search_and_func,
        search_or_func,
        search_phrase_func,
        find_context_func,
    ) -> list[dict]:
        """
        –õ–∏–Ω–µ–π–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É —Ñ–∞–π–ª–æ–≤.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ fallback —É—Ä–æ–≤–µ–Ω—å 2, –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.

        Args:
            directory: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            mode: –†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ ("AND", "OR", "PHRASE")
            tokens_or_phrase: –¢–æ–∫–µ–Ω—ã –∏–ª–∏ —Ñ—Ä–∞–∑–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            search_and_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ AND
            search_or_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ OR
            search_phrase_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ PHRASE
            find_context_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ —Å –ø—É—Ç—è–º–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if directory is None or not isinstance(directory, Path):
            logger.warning("–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä directory –≤ _linear_search_in_cache")
            return []
        if not query or not isinstance(query, str) or not query.strip():
            logger.warning("–ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –≤ _linear_search_in_cache")
            return []
        if limit <= 0:
            limit = DEFAULT_SEARCH_LIMIT
        if mode not in {"AND", "OR", "PHRASE"}:
            logger.warning(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞: {mode}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è AND")
            mode = "AND"

        results = []
        query_lower = query.lower()

        for rel_path, content in self.content_cache.items():
            if len(results) >= limit:
                break

            full_path = directory / rel_path
            if not full_path.exists():
                continue

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞
            match = self._apply_search_mode(
                content, mode, tokens_or_phrase,
                search_and_func, search_or_func, search_phrase_func
            )

            if match:
                context_lines = find_context_func(
                    content, query, mode, tokens_or_phrase
                )
                context = "\n".join(context_lines)
                score = self._calculate_document_score(rel_path)

                results.append(
                    {
                        "path": rel_path,
                        "title": full_path.name,
                        "context": context,
                        "score": score,
                    }
                )

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score
        results.sort(key=lambda x: x.get("score", 0), reverse=True)
        return results

    def _grep_search_in_files(
        self,
        directory: Path,
        query: str,
        mode: str,
        tokens_or_phrase: list[str] | str,
        limit: int,
        search_and_func,
        search_or_func,
        search_phrase_func,
        find_context_func,
    ) -> list[dict]:
        """
        –ü—Ä–æ—Å—Ç–æ–π grep-–ø–æ–¥–æ–±–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ñ–∞–π–ª–∞–º.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ fallback —É—Ä–æ–≤–µ–Ω—å 3 (–ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑–µ—Ä–≤), –µ—Å–ª–∏ –∫—ç—à –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.

        Args:
            directory: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            mode: –†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ ("AND", "OR", "PHRASE")
            tokens_or_phrase: –¢–æ–∫–µ–Ω—ã –∏–ª–∏ —Ñ—Ä–∞–∑–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            search_and_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ AND
            search_or_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ OR
            search_phrase_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ PHRASE
            find_context_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ —Å –ø—É—Ç—è–º–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if directory is None or not isinstance(directory, Path):
            logger.warning("–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä directory –≤ _grep_search_in_files")
            return []
        if not query or not isinstance(query, str) or not query.strip():
            logger.warning("–ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –≤ _grep_search_in_files")
            return []
        if limit <= 0:
            limit = DEFAULT_SEARCH_LIMIT
        if mode not in {"AND", "OR", "PHRASE"}:
            logger.warning(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞: {mode}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è AND")
            mode = "AND"

        results = []
        query_lower = query.lower()

        # –ò—â–µ–º –≤—Å–µ .md —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for file_path in directory.rglob("*.md"):
            if len(results) >= limit:
                break

            if not file_path.is_file():
                continue

            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
                content = self._load_content(file_path)
                rel_path = self._get_relative_path(file_path, directory)

                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞
                match = False
                if mode == "PHRASE":
                    match = search_phrase_func(content, str(tokens_or_phrase))
                elif mode == "AND" and isinstance(tokens_or_phrase, list):
                    match = search_and_func(content, tokens_or_phrase)
                elif mode == "OR" and isinstance(tokens_or_phrase, list):
                    match = search_or_func(content, tokens_or_phrase)

                if match:
                    context_lines = find_context_func(
                        content, query, mode, tokens_or_phrase
                    )
                    context = "\n".join(context_lines)
                    score = self._calculate_document_score(rel_path)

                    results.append(
                        {
                            "path": rel_path,
                            "title": file_path.name,
                            "context": context,
                            "score": score,
                        }
                    )

                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –¥–ª—è –±—É–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                    self._evict_cache_if_needed()
                    self.content_cache[rel_path] = content
                    self.file_mtimes[rel_path] = file_path.stat().st_mtime
                    self._update_index_for_file(rel_path, content)

            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ grep-–ø–æ–∏—Å–∫–µ –≤ {file_path}: {e}")
                continue

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score
        results.sort(key=lambda x: x.get("score", 0), reverse=True)
        return results

    def search_in_directory(
        self,
        directory: Path,
        query: str,
        mode: str = "AND",
        limit: int = DEFAULT_SEARCH_LIMIT,
        tokenize_query_func=None,
        search_and_func=None,
        search_or_func=None,
        search_phrase_func=None,
        find_context_func=None,
    ) -> list[dict]:
        """
        –ü–æ–∏—Å–∫ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–Ω–¥–µ–∫—Å–∞.

        Args:
            directory: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            mode: –†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ ("AND", "OR", "PHRASE")
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            tokenize_query_func: –§—É–Ω–∫—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞
            search_and_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ AND
            search_or_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ OR
            search_phrase_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ —Ä–µ–∂–∏–º–µ PHRASE
            find_context_func: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ —Å –ø—É—Ç—è–º–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not isinstance(directory, Path):
            directory = Path(directory)

        if not directory.exists():
            logger.warning(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {directory}")
            return []

        if not isinstance(query, str) or not query.strip():
            logger.warning("–ü—É—Å—Ç–æ–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
            return []

        if limit <= 0:
            limit = DEFAULT_SEARCH_LIMIT

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ mcp_index
        if tokenize_query_func is None:
            from mcp_index import _tokenize_query

            tokenize_query_func = _tokenize_query

        if search_and_func is None:
            from mcp_index import _search_and

            search_and_func = _search_and

        if search_or_func is None:
            from mcp_index import _search_or

            search_or_func = _search_or

        if search_phrase_func is None:
            from mcp_index import _search_phrase

            search_phrase_func = _search_phrase

        if find_context_func is None:
            from mcp_index import _find_context_lines

            find_context_func = _find_context_lines

        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
        explicit_mode = mode != "AND"
        search_mode, tokens_or_phrase = tokenize_query_func(query, mode, explicit_mode)

        # –£—Ä–æ–≤–µ–Ω—å 1: –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        if self._is_index_available():
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
                candidate_files = set()

                if search_mode == "PHRASE":
                    # –î–ª—è PHRASE mode –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫—ç—à—É
                    phrase = str(tokens_or_phrase)
                    for rel_path, content in self.content_cache.items():
                        full_path = directory / rel_path
                        if full_path.exists() and search_phrase_func(content, phrase):
                            candidate_files.add(rel_path)
                elif search_mode == "AND" and isinstance(tokens_or_phrase, list):
                    # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
                    if tokens_or_phrase:
                        candidate_files = set(
                            self.inverted_index.get(tokens_or_phrase[0].lower(), set())
                        )
                        for token in tokens_or_phrase[1:]:
                            candidate_files &= self.inverted_index.get(
                                token.lower(), set()
                            )
                elif search_mode == "OR" and isinstance(tokens_or_phrase, list):
                    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤ —Ñ–∞–π–ª–æ–≤
                    for token in tokens_or_phrase:
                        candidate_files |= self.inverted_index.get(
                            token.lower(), set()
                        )

                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                results = []
                for rel_path in candidate_files:
                    if len(results) >= limit:
                        break

                    full_path = directory / rel_path
                    if not full_path.exists():
                        continue

                    try:
                        content = self._get_content(full_path, directory)

                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –¥–ª—è —Ç–æ—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                        match = False
                        if search_mode == "PHRASE":
                            match = search_phrase_func(content, str(tokens_or_phrase))
                        elif search_mode == "AND" and isinstance(
                            tokens_or_phrase, list
                        ):
                            match = search_and_func(content, tokens_or_phrase)
                        elif search_mode == "OR" and isinstance(
                            tokens_or_phrase, list
                        ):
                            match = search_or_func(content, tokens_or_phrase)

                        if match:
                            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                            context_lines = find_context_func(
                                content, query, search_mode, tokens_or_phrase
                            )
                            context = "\n".join(context_lines)

                            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
                            score = self._calculate_document_score(rel_path)

                            results.append(
                                {
                                    "path": rel_path,
                                    "title": full_path.name,
                                    "context": context,
                                    "score": score,
                                }
                            )
                    except Exception as e:
                        logger.warning(
                            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ–∏—Å–∫–∞ {rel_path}: {e}"
                        )
                        continue

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ score –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è
                results.sort(key=lambda x: x.get("score", 0), reverse=True)

                if results:
                    return results
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —á–µ—Ä–µ–∑ –∏–Ω–¥–µ–∫—Å (—É—Ä–æ–≤–µ–Ω—å 1): {e}")

        # –£—Ä–æ–≤–µ–Ω—å 2: –õ–∏–Ω–µ–π–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫—ç—à—É
        if len(self.content_cache) > 0:
            try:
                results = self._linear_search_in_cache(
                    directory,
                    query,
                    search_mode,
                    tokens_or_phrase,
                    limit,
                    search_and_func,
                    search_or_func,
                    search_phrase_func,
                    find_context_func,
                )
                if results:
                    logger.info("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback —É—Ä–æ–≤–µ–Ω—å 2 (–ª–∏–Ω–µ–π–Ω—ã–π –ø–æ–∏—Å–∫)")
                    return results
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–∏–Ω–µ–π–Ω–æ–º –ø–æ–∏—Å–∫–µ (—É—Ä–æ–≤–µ–Ω—å 2): {e}")

        # –£—Ä–æ–≤–µ–Ω—å 3: Grep-–ø–æ–∏—Å–∫ –ø–æ —Ñ–∞–π–ª–∞–º
        try:
            results = self._grep_search_in_files(
                directory,
                query,
                search_mode,
                tokens_or_phrase,
                limit,
                search_and_func,
                search_or_func,
                search_phrase_func,
                find_context_func,
            )
            if results:
                logger.info("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback —É—Ä–æ–≤–µ–Ω—å 3 (grep-–ø–æ–∏—Å–∫)")
                return results
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ grep-–ø–æ–∏—Å–∫–µ (—É—Ä–æ–≤–µ–Ω—å 3): {e}")

        # –ï—Å–ª–∏ –≤—Å–µ —É—Ä–æ–≤–Ω–∏ –Ω–µ –¥–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        return []
